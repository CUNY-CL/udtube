checkpoint:
  monitor: val_loss
  save_last: link
data:
  batch_size: 5  # 2 batches per epoch.
model:
  encoder_optimizer:
    class_path: torch.optim.Adam
    init_args:
      lr: 1e-4
  encoder_scheduler:
    class_path: udtube.schedulers.WarmupInverseSquareRoot
    init_args:
      warmup_epochs: 3
  classifier_optimizer:
    class_path: torch.optim.Adam
    init_args:
      lr: 1e-2
seed_everything: 42
trainer:
  deterministic: true  # Slower but we're testing...
  enable_progress_bar: false
  max_epochs: 10
  precision: bf16-mixed
